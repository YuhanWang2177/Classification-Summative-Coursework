---
title: "Summative assignment for ASML Regression"
author: "Yuhan Wang"
output:
  pdf_document: default
  html_document:
    df_print: paged
  html_notebook:
    df_print: paged
  word_document: default
---


# General Instructions

Please go through the R notebook below, and carry out the requested tasks. You will provide all your answers directly into this .Rmd file. Add code into the R chunks where requested. You can create new chunks where required. Where text answers are requested, please add them directly into this document, typically below the R chunks, using R Markdown syntax as appropriate.

At the end, you will submit a `knitted' PDF version of this file through Gradescope.

**Important**: Please ensure carefully that all chunks compile, and also check in the knitted PDF whether all R chunks did *actually* compile, and all images that you would like to produce have *actually* been generated.  **An R chunk which does not compile will give zero marks, and a picture which does not exist will give zero marks, even if some parts of the required code are correct.**

**Note**: It is appreciated that some of the requested analyses requires running R code which is not deterministic. So, you will not have full control over the output that is finally generated in the knitted document. This is fine. It is clear that the methods under investigation carry uncertainty, which is actually part of the problem tackled in this assignment. Your analysis should, however, be robust enough so that it stays in essence correct under repeated execution of your data analysis.

# Reading in data

We consider data from an industrial melter system. The melter is part of a disposal procedure, where a powder (waste material) is clad in glass. The melter vessel is
continuously filled with powder, and raw glass is discretely introduced in the form of glass frit. This binary composition is heated by induction coils, positioned around the melter vessel. Resulting from this heating procedure, the glass becomes
molten homogeneously [(Liu et al, 2008)](https://aiche.onlinelibrary.wiley.com/doi/full/10.1002/aic.11526).

Measurements of 15 temperature sensors `temp1`, ..., `temp15` (in $^{\circ} C$), the power in four induction coils `ind1`,...,  `ind4`,  the `voltage`, and the `viscosity` of the molten glass, were taken every 5 minutes. The sample size available for our analysis is $n=900$.

We use the following R chunk to read the data in
```{r}
melter = read.table("http://maths.dur.ac.uk/~dma0je/Data/melter.dat", header=TRUE)
```

If this has gone right, then the following code
```{r}
is.data.frame(melter)
dim(melter)
```
should tell you that `melter` is a data frame of dimension $900 \times 21$. Otherwise something has gone wrong, and you need to start again.

To get more familiar with the data frame, please also execute
```{r}
head(melter)
colnames(melter)
boxplot(melter)
```


# Task 1: Principal component analysis (5 marks)

We consider initially only the 15 variables representing the temperature sensors. Please create a new data frame, called `Temp`, which contains only these 15 variables. Then carry out a principal component analysis. Use your judgement on whether, for this purpose, the temperature variables require scaling or not and explain your reasoning. Next, produce a screeplot, and answer the following questions: How many principal components are needed to capture 90% of the total variation? How many are needed to capture 98%?

**Answer:**

```{r}
# ---
library(stats)

#Create Temp data frame by index to get temperature
Temp <- melter[c(-1,-2,-3,-4,-5,-6)] 

# Standardisation of data frames
temp_data_scaled <- scale(Temp)

pca <- princomp(temp_data_scaled)
summary(pca)
screeplot(pca,npcs = 15, type="barplot")


cumulative_variance <- cumsum(pca$sdev^2 / sum(pca$sdev^2))
n_components_90 <- min(which(cumulative_variance >= 0.9))
n_components_98 <- min(which(cumulative_variance >= 0.98))


cat("Need", n_components_90, "principal components to capture 90% of the total variation. \n")
cat("Need", n_components_98, "principal components to capture 98% of the total variation. \n")
```


# Task 2: Multiple linear regression (20 marks)

We consider from now on, and for the remainder of this assignment, `viscosity` as the response variable.

Fit a linear regression model, with `viscosity` as response variable, and all other variables as predictors, and  produce the `summary` output of the fitted model. In this task, we are mainly interested in the standard errors of the estimated coefficients. Create a vector, with name `melter.fit.sd`, which contains the standard errors of all estimated coefficients, except the intercept. (So, this vector should have length 20). Then produce a `barplot` of these standard errors (where the height of each bar indicates the value of the standard error of the respective coefficients). Please use blue color to fill the bars of the barplot.

**Answer:**

```{r}
#---

# Fitting a linear regression model
fit <- lm(viscosity ~ ., data = melter)
summary(fit)

# Extract the standard error of all coefficients except the intercept
se <- summary(fit)$coef[-1, "Std. Error"]

# Create vector melt.fit.sd
melt.fit.sd <- as.vector(se)

barplot(melt.fit.sd, col = "blue", main = "Standard Errors of Coefficients (Excluding Intercept)")

```

Now repeat this analysis, but this time using `jags` to implement a Bayesian linear regression. You should state explicitly in your answer the prior distributions you use in your `jags` model. 

Run four MCMC chains and then extract the posterior draws from the fitted object. Explain how you verified the mixing and convergence of your chains. You should illustrate your answer by: (i) producing a multi-panel plot showing the trace plot, ACF plot and marginal density plots for three parameters of your choice; (ii) calculating the effective sample size of all parameters.

**Answer**:

```{r}
#---
library(durhamSLR)
library(rjags)
library(coda)

data <- melter
  
#define model
model_string <- "
model {
  #prior distributions
  for (i in 1:p) {
    beta[i] ~ dnorm(0, 0.001)
    mu[i] ~ dunif(0, 1)
  }
  sigma2 ~ dgamma(0.001, 0.001)
  tau2 ~ dgamma(0.001, 0.001) 
  beta_0 ~ dnorm(0, 0.001)

  #Likelihood function
  for (j in 1:n) {
    y[j] ~ dnorm(beta_0 + inprod(beta[], x[j,]), tau2)
    for (i in 1:p) {
      x[j,i] ~ dbern(mu[i])
    }
  }
}"



data_list <- list(
  y = data[,1],
  x = data[,2:21],
  n = nrow(data),
  p = ncol(data) - 1
)

# JAGS model
nchains <-  4 

model1 <- jags.model(textConnection(model_string), data = data_list, n.chains=nchains)
update(model1, 10000)

postmod1.samples = coda.samples(model1, c("beta"), 10000)

# extract MCMC
tabular_mcmc = array(NA, c(nrow(postmod1.samples[[1]]), nchains, ncol(postmod1.samples[[1]])))

dimnames(tabular_mcmc) = list(iterations=NULL, chains=paste("chain:", 1:nchains, sep=""),
parameters=colnames(postmod1.samples[[1]]))
for(i in 1:nchains) {
tabular_mcmc[,i,] = as.matrix(postmod1.samples[[i]])
}

diagnostics(tabular_mcmc)

#  MCMC output
summary(postmod1.samples)
apply(tabular_mcmc, 3, mean)
effectiveSize(postmod1.samples)

```

Now compute the posterior standard deviations for the coefficients using the MCMC output after pooling the samples from the four chains. Please save these standard deviations, again excluding that for the intercept, into a vector `melter.bayes.sd`.  Now produce a barplot which displays both of `melter.fit.sd` and `melter.bayes.sd` in one plot, and allows a direct comparison of the frequentist and Bayesian standard errors (by having the corresponding bars for both methods directly side-by-side, with the Bayesian ones in red color). The barplot should be equipped with suitable labels and legends to enable good readability. Comment on the outcome.

**Answer**:

```{r}
#---
melt.bayes.sd<- c(0.1162,1.9515,2.1927,3.9615,2.3582,0.9848,1.2301,0.6174,0.3434,0.2799,0.5566,0.3672,0.4696,0.4437,0.7003,0.3767,0.5651,0.3491,0.4829,0.5350)

sd_matrix <- cbind(melt.fit.sd, melt.bayes.sd)

barplot(sd_matrix, beside = TRUE, col = c("gray", "red"), 
        xlab = "Coefficient", ylab = "Standard Error",
        names.arg = colnames(melt.bayes.sd))
        
legend("topright", legend = c("melt.fit.sd", "melt.bayes.sd"), 
       fill = c("gray", "red"))

#If the posterior standard deviation of the Bayesian approach is greater than the standard error of the frequency approach, then this indicates that the Bayesian approach is more susceptible to the effects of under-sampling. 

#In addition, if the standard deviation of the Bayesian approach is significantly smaller than the standard error, this indicates that the Bayesian approach makes better use of the information available and therefore estimates the parameters more accurately.

```

# Task 3: The Lasso (25 marks)

We would like to reduce the dimension of the currently 20-dimensional space of predictors. We employ the LASSO to carry out this task. Carry out this analysis, which should feature the following elements:

 * the trace plot of the fitted coefficients, as a function of $\log(\lambda)$, with $\lambda$ denoting the penalty parameter;
 * a graphical illustration of the cross-validation to find $\lambda$;
 * the chosen value of $\lambda$ according to the `1-se` criterion, and a brief explanation of what this criterion actually does and why it is appropriate here;
 * the fitted coefficients according to this choice of $\lambda$.

**Answer:**

```{r}
#---
data <- melter

response <- as.matrix(data[,1])
predictors <- as.matrix(data[,2:21])

# Using the glmnet package for lasso regression and outputting results
library(glmnet)
lasso <- glmnet(predictors, response, alpha = 1)
print(lasso)

# Selecting the optimal lambda value using cross-validation
cv <- cv.glmnet(predictors, response, alpha = 1)
plot(cv)
best_lambda <- cv$lambda.min

# Rerun lasso regression based on optimal lambda values and output
lasso_best <- glmnet(predictors, response, alpha = 1, lambda = best_lambda)
print(lasso_best)


plot(lasso_best, xvar="lambda", label=TRUE)

coef(lasso_best)
```

Next, carry out a Bayesian analysis of the lasso using the `monomvn` package. Use the help file for the `blasso` function to identify the prior used for the intercept, coefficients, error variance and lasso penalty parameter. Then run one MCMC chain and extract the posterior draws for the intercept, coefficients, error variance and the lasso penalty parameter. After omitting the burn-in draws, check the convergence and mixing of your MCMC chain and calculate the effective sample size of all parameters.

**Answer:**

```{r}
#---
library(monomvn)
library(glmnet)

help(blasso)

x <- melter[-1]
y <-as.matrix(melter$viscosity)

#Bayesian regression
reg.blas <- blasso(x, y)

plot(reg.blas, burnin=200)
legend("topleft", c("blasso-map"),
       col=c(2), pch=c(21))

plot(reg.blas, burnin=200, which="m")


s <- summary(reg.blas, burnin=200)

# calculate the probability that each beta coef != zero
s$bn0

# summarize s2
plot(reg.blas, burnin=200, which="s2")
s$s2

# summarize lambda2
plot(reg.blas, burnin=200, which="lambda2")
s$lambda2


# (~400-times slower due to automatic thinning level)
regt.blas <- blasso(x, y, theta=0.1)

# plotting some information about nu, and quantiles
plot(regt.blas, "nu", burnin=200)
quantile(regt.blas$nu[-(1:200)], c(0.05, 0.95))

# Bayes Factor shows strong evidence for Student-t model
mean(exp(regt.blas$llik[-(1:200)] - regt.blas$llik.norm[-(1:200)]))
```

Executing the code
```{r, eval=FALSE}
getS3method("plot", "blasso")
```
prints the source code for the `plot` method when applied to objects returned by the `blasso` function. Use this code to explain how the MAP estimate of the model parameters is obtained. Next, visualize the full posterior distributions of all coefficients (except the intercept) in terms of boxplots and use your answer from the previous part to mark the MAP estimates of the coefficients on the plot using the `points` function. Also visualize the resulting standard errors of the coefficients using a barplot (with red bars).

Give an interpretation of the results, especially in terms of the evidence that this analysis gives in terms of inclusion/non-inclusion of certain variables.

**Answer:**

```{r}
#---
x <- melter[-1]
y <-as.matrix(melter$viscosity)
data <- data.frame(x,y)

# Bayesian Lasso regression
reg.blas <- blasso(x, y)

plot(reg.blas)

summary(reg.blas)$coef
```


# Task 4: Bootstrap (15 marks)

A second possibility to assess uncertainty of any estimator is the Bootstrap. Implement a nonparametric bootstrap procedure to assess the uncertainty of your frequentist lasso fit from Task 3.

Produce boxplots of the full bootstrap distributions for all coefficients (except the intercept).

Then, add (green) bars with the resulting standard errors to the barplot produced in Task 3, allowing for comparison between Bootstrap and Bayesian standard errors. Interpret the results.

**Answer:**


```{r}
#---
data <- melter

response <- as.matrix(data[,1])
predictors <- as.matrix(data[,2:21])

library(glmnet)
library(boot)

# Calculation of standard errors
fit <- glmnet(predictors,response, alpha = 1)
std_err <- c(as.matrix(coef(fit)[-1][c(1:900)]) / sqrt(length(c(response))))

barplot(std_err, main = "Standard Error of LASSO coefficients", 
        ylab = "Standard Error", xlab = "Coefficient index", col = "green")


boot_coef <- function(data, index) {
  fit <- glmnet(as.matrix(data[index,-1]), as.vector(data[index,1]), alpha = 1)
  coef(fit)[-1][c(1:900)] #
}

boot_result <- boot(data, boot_coef, R = 1000)


boxplot(boot_result$t, main = "Bootstrap distribution of LASSO coefficients", 
        ylab = "Coefficient value", xlab = "Coefficient index", col = "lightblue")
```



# Task 5: Model choice (10 marks)

Based on all considerations and analyses carried out so far, decide on a suitable model that you would present to a client, if you had been the statistical consultant.

Formulate the model equation in mathematical notation.

Refit your selected model using ordinary Least Squares. Carry out some residual diagnostics for this fitted model, and display the results. Discuss these briefly.

**Answer:**

```{r}
#---
coef(lasso_best)

#For the model choice, a modified lasso regression model can be chosen.

#lasso regression is characterised by variable screening and complexity adjustment while fitting a generalised linear model.

#It avoids the pitfalls of incorrect selection of the prior distribution in Bayesian regression and overfitting in ordinary linear regression. Based on the answers in task 3, we can wirte regression equation.


```

We will refer to the model produced in this task as (T5) henceforth.


# Task 6: Extensions (25 marks)

For this task, take the model (T5) as the starting point.  Then consider extensions of your model in TWO of the following THREE directions (of your choice).

(1) Replace the temperature sensor variables in model (T5) by an adequate number of principal components (see Task 1).

(2) Replace the `voltage`, and the remaining induction variables, by nonparametric terms.


(3) Consider a transformation of the response variable `viscosity`.

Each time, report the fitted model through adequate means. Discuss whether the corresponding extension is useful, giving quantitative or graphical evidence where possible.

Give a short discussion on whether any of your extensions have led to an actual improvement compared to model (T5).

**Answer:**

```{r}
#---
library(stats)

data <- melter[-1] 
data_scaled <- scale(data)

pca <- princomp(data_scaled)
summary(pca)

plot(pca)

cumulative_variance <- cumsum(pca$sdev^2 / sum(pca$sdev^2))
n_components_90 <- min(which(cumulative_variance >= 0.9))
n_components_98 <- min(which(cumulative_variance >= 0.98))

cat("Need", n_components_90, "principal components to capture 90% of the total variation. \n")
cat("Need", n_components_98, "principal components to capture 98% of the total variation. \n")
```


```{r}

data <- melter

response <- scale(as.matrix(data[,1]))
predictors <- as.matrix(data[,2:21])

library(glmnet)
lasso <- glmnet(predictors, response, alpha = 1)
print(lasso)

cv <- cv.glmnet(predictors, response, alpha = 1)
plot(cv)
best_lambda <- cv$lambda.min

lasso_best <- glmnet(predictors, response, alpha = 1, lambda = best_lambda)
print(lasso_best)

plot(lasso_best, xvar="lambda", label=TRUE)

coef(lasso_best)
```



